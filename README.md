# ML Regression with numpy

This code was created with the main goal to show how to build an ML regression model with gradient descent for the optimization part.

The definition of the problem was got it from the portal of https://dataflowr.github.io/website/modules/2b-automatic-differentiation/

The equation model is: $y_{t} = 2x_{t}^{1} - 3x_{t}^{2} + 1, t$ $\epsilon$ $\{ 1,...,30 \}$
